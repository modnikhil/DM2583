{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nikhil Modak\n",
    "Adriana Ixba\n",
    "Carlos Valdez\n",
    "Group 2\n",
    "\n",
    "\n",
    "# Using Naive Bayes for Sentiment Analysis Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Diagram\n",
    "\n",
    "\n",
    "![](data/diagram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "\n",
    "For vectorization, we didn't utilize a library to do so. We instead implemented our own feature frequency matrix that allowed us to view the amount of times a word appeared in a certain class (Positive/Negative). This 2-D matrix made it possible to calculate the Priors and Likelihoods of each class and word. This matrix was implemented as a list of dictionaries. The list was indexed by class (0 == Positive, 1 == Negative), and the dictionaries contained tuples of type {string, int} where the key represented a unique feature (word in a sentence), and the value represented the frequency of that feature in a given class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python data clean up \n",
    "We first separated reviews and scores, replaced the '<br />' tags spread out through the text file, removed the line endings and used filter instead of just using review.split() - at first we didn't check our data and we discovered that empty string objects were being tested by our classifier, but after we fixed this using filter(), we saw a 2-3 percent increase in accuracy. \n",
    "\n",
    "Final clean up code listed below, used for both the training and the test data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/clean_up.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe the sklearn functions we used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Our accuracy originally started off at about  40%. \n",
    "\n",
    "Later on, we began using stopwords (words which do not give a specific clue to what the rating could be) , and implementing additive smoothing in order to help get a better balance of results.  This brought our results up to 54% accuracy. \n",
    "![](data/stopwords.png)\n",
    "\n",
    "This was a significant increase since it indicated we were on the right track. We then found out that we could improve our method of additive smoothing. Initially, we were simply adding 1 to the numerator and 1 to the denominator when calculating the likelihood of a word given a class, but we realized we could improve this by adding the size of our class dictionary to the denominator as well, reducing the likelihood of words that don't show up in our train_set for a given class. \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Results from booking.com\n",
    "At the end we  were able to achieve an 81% accuracy on our trained dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/confusion_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted  Negative  Positive\n",
    "# Actual                       \n",
    "# Negative          7        14\n",
    "# Positive          5        74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
